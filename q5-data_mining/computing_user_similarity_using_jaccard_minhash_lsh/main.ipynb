{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d3f3c40",
   "metadata": {},
   "source": [
    "# User Similarity Using Jaccard, MinHash & LSH\n",
    "\n",
    "> *Data Mining*  \n",
    "> *MSc in Data Science, Department of Informatics*  \n",
    "> *Athens University of Economics and Business*\n",
    "\n",
    "---\n",
    "\n",
    "## *Table of Contents*\n",
    "\n",
    "- [*1. Introduction*](#introduction)\n",
    "    - [*1.1. Libraries*](#libraries)\n",
    "    - [*1.2. Data*](#data)\n",
    "    - [*1.3. Data Preprocessing*](#data_preprocessing)\n",
    "- [*2. Compute Exact Jaccard Similarity*](#jaccard_similarity)\n",
    "- [*3. Compute Similarity Using MinHash Signatures*](#minhash_similarity)\n",
    "    - [*3.1. Using 50 Hash Functions*](#50_hash_functions)\n",
    "    - [*3.2. Using 100 Hash Functions*](#100_hash_functions)\n",
    "    - [*3.3. Using 200 Hash Functions*](#200_hash_functions)\n",
    "    - [*3.4. Comments*](#comments_1)\n",
    "- [*4. Locate Similar Users Using LSH Index*](#lsh_similarity)\n",
    "    - [*4.1. LSH Instance 1*](#lsh_instance_1)\n",
    "    - [*4.2. LSH Instance 2*](#lsh_instance_2)\n",
    "    - [*4.3. Comments*](#comments_2)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bd39ed",
   "metadata": {},
   "source": [
    "## *Introduction* <a class='anchor' id='introduction'></a>\n",
    "\n",
    "### *Libraries* <a class='anchor' id='libraries'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4833f382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "from functions.data_preprocessing import *\n",
    "from functions.jaccard_similarity import *\n",
    "from functions.min_hash_similarity import *\n",
    "from functions.lsh_similarity import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94015df",
   "metadata": {},
   "source": [
    "### *Data* <a class='anchor' id='data'></a>\n",
    "\n",
    "*The following two datasets will be used:*\n",
    "- *`ratings.txt`*\n",
    "- *`movies.txt`*\n",
    "\n",
    "##### *Read ratings data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01ff1f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratings.shape: (100000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating\n",
       "0      196       242       3\n",
       "1      186       302       3\n",
       "2       22       377       1\n",
       "3      244        51       2\n",
       "4      166       346       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filepath\n",
    "filepath = './data/ratings.txt'\n",
    "\n",
    "# read the dataset\n",
    "ratings = pd.read_csv(filepath, sep='\\t', header=None, usecols=[0,1,2], names=['user_id','movie_id','rating'])\n",
    "\n",
    "# shape\n",
    "print(f'ratings.shape: {ratings.shape}')\n",
    "\n",
    "# preview\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796eb5a3",
   "metadata": {},
   "source": [
    "##### *Read movies data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87806c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies.shape: (1682, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id              title\n",
       "0         1   Toy Story (1995)\n",
       "1         2   GoldenEye (1995)\n",
       "2         3  Four Rooms (1995)\n",
       "3         4  Get Shorty (1995)\n",
       "4         5     Copycat (1995)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filepath\n",
    "filepath = './data/movies.txt'\n",
    "\n",
    "# read the dataset\n",
    "movies = pd.read_csv(filepath, sep='|', header=None, usecols=[0,1], names=['movie_id','title'], encoding='latin-1')\n",
    "\n",
    "# shape\n",
    "print(f'movies.shape: {movies.shape}')\n",
    "\n",
    "# preview\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5ff1d1",
   "metadata": {},
   "source": [
    "### *Data Preprocessing* <a class='anchor' id='data_preprocessing'></a>\n",
    "\n",
    "- *In this step, we will preprocess the `ratings` dataframe*\n",
    "- *In particular, we will transform its data into a `dictionary` format*\n",
    "- *The keys of the dictionary will correspond to each user ID, while the values will be arrays containing all the movie IDs seen from each respective user*\n",
    "\n",
    "##### *Preprocess `ratings`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "147b6323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# execute function\n",
    "user_movies = load_movies(ratings.iloc[:,:2])\n",
    "\n",
    "# preview\n",
    "len(user_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1f6f95",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## *Compute Exact Jaccard Similarity* <a class='anchor' id='jaccard_similarity'></a>\n",
    "\n",
    "##### *Compute user similarity using Jaccard coefficient*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "080b5feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute function\n",
    "jaccard_sim, jaccard_sim_threshold = user_similarity_using_jaccard_coefficient(user_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e819618",
   "metadata": {},
   "source": [
    "##### *Display pair of users with a similarity score of at least 50%*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c3dac6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408_898: 0.8387096774193549\n",
      "328_788: 0.6729559748427673\n",
      "489_587: 0.6299212598425197\n",
      "600_826: 0.5454545454545454\n",
      "451_489: 0.5333333333333333\n",
      "674_879: 0.5217391304347826\n",
      "554_764: 0.5170068027210885\n",
      "197_826: 0.512987012987013\n",
      "197_600: 0.5\n",
      "800_879: 0.5\n"
     ]
    }
   ],
   "source": [
    "# pair of users: similarity\n",
    "for k,v in jaccard_sim_threshold.items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240e5561",
   "metadata": {},
   "source": [
    "##### *Get the movies seen from the most similar pair of users*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c277bfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar pair of users: 408 - 898\n",
      "\n",
      "Movies seen from the most similar pair of users:\n",
      "\n",
      " 242: Kolya (1996)\n",
      " 243: Jungle2Jungle (1997)\n",
      " 258: Contact (1997)\n",
      " 270: Gattaca (1997)\n",
      " 271: Starship Troopers (1997)\n",
      " 272: Good Will Hunting (1997)\n",
      " 286: English Patient, The (1996)\n",
      " 288: Scream (1996)\n",
      " 294: Liar Liar (1997)\n",
      " 300: Air Force One (1997)\n",
      " 302: L.A. Confidential (1997)\n",
      " 309: Deceiver (1997)\n",
      " 310: Rainmaker, The (1997)\n",
      " 312: Midnight in the Garden of Good and Evil (1997)\n",
      " 313: Titanic (1997)\n",
      " 315: Apt Pupil (1998)\n",
      " 316: As Good As It Gets (1997)\n",
      " 319: Everyone Says I Love You (1996)\n",
      " 324: Lost Highway (1997)\n",
      " 327: Cop Land (1997)\n",
      " 328: Conspiracy Theory (1997)\n",
      " 334: U Turn (1997)\n",
      " 343: Alien: Resurrection (1997)\n",
      " 347: Wag the Dog (1997)\n",
      " 358: Spawn (1997)\n",
      " 539: Mouse Hunt (1997)\n",
      " 683: Rocket Man (1997)\n",
      " 689: Jackal, The (1997)\n",
      " 748: Saint, The (1997)\n",
      " 751: Tomorrow Never Dies (1997)\n",
      "1296: Indian Summer (1996)\n"
     ]
    }
   ],
   "source": [
    "# execute function\n",
    "get_the_movies_of_the_most_similar_pair_of_users(movies, jaccard_sim, user_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a70bd2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## *Compute Similarity Using MinHash Signatures* <a class='anchor' id='minhash_similarity'></a>\n",
    "\n",
    "### *Using 50 Hash Functions* <a class='anchor' id='50_hash_functions'></a>\n",
    "\n",
    "##### *Compute user similarity using MinHash signatures*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8497850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute function\n",
    "minhash_sim_50, minhash_sim_50_threshold = user_similarity_using_min_hash_signatures(user_movies,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec38a56",
   "metadata": {},
   "source": [
    "##### *Display pair of users with a similarity score of at least 50%*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "436a3db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328_788: 0.5151515151515151\n",
      "408_898: 0.5151515151515151\n"
     ]
    }
   ],
   "source": [
    "# pair of users: similarity\n",
    "for k,v in minhash_sim_50_threshold.items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f845c451",
   "metadata": {},
   "source": [
    "##### *Report the number of False Positives (FP) and False Negatives (FN) (against the exact Jaccard similarity)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbd22508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 42218 False Positives (FP) and 386217 False Negatives (FN) (against the exact Jaccard similarity).\n"
     ]
    }
   ],
   "source": [
    "# execute function\n",
    "FP, FN = compute_the_number_of_false_positives_and_false_negatives(jaccard_sim, minhash_sim_50)\n",
    "\n",
    "# print\n",
    "print(f'There are {FP} False Positives (FP) and {FN} False Negatives (FN) (against the exact Jaccard similarity).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a70e66d",
   "metadata": {},
   "source": [
    "##### *Report the average number of False Positives (FP) and False Negatives (FN) for 5 different runs using different functions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05bed35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of False Positives is 36228, while the average number of False Negatives is 392275.\n",
      "\n",
      "Elapsed time: 59 secs.\n"
     ]
    }
   ],
   "source": [
    "# start time\n",
    "st = time.time()\n",
    "\n",
    "# initialize empty lists\n",
    "# to store FP and FN values\n",
    "false_positives = []\n",
    "false_negatives = []\n",
    "\n",
    "for i in range(5):\n",
    "    # compute user similarity using MinHash signatures\n",
    "    minhash_sim_50, minhash_sim_50_threshold = user_similarity_using_min_hash_signatures(user_movies,50)\n",
    "    # compute false positives and false negatives\n",
    "    FP, FN = compute_the_number_of_false_positives_and_false_negatives(jaccard_sim, minhash_sim_50)\n",
    "    # append the values from each iteration\n",
    "    false_positives.append(FP)\n",
    "    false_negatives.append(FN)\n",
    "\n",
    "# calculate the averages\n",
    "FP_avg = round(np.mean(false_positives))\n",
    "FN_avg = round(np.mean(false_negatives))\n",
    "\n",
    "# end time\n",
    "et = time.time()\n",
    "\n",
    "# print\n",
    "print(f'The average number of False Positives is {FP_avg}, while the average number of False Negatives is {FN_avg}.')\n",
    "print()\n",
    "print(f'Elapsed time: {round(et-st)} secs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9ab883",
   "metadata": {},
   "source": [
    "### *Using 100 Hash Functions* <a class='anchor' id='100_hash_functions'></a>\n",
    "\n",
    "##### *Compute user similarity using MinHash signatures*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3eb2a67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute function\n",
    "minhash_sim_100, minhash_sim_100_threshold = user_similarity_using_min_hash_signatures(user_movies,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e8b080",
   "metadata": {},
   "source": [
    "##### *Display pair of users with a similarity score of at least 50%*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c2673e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408_898: 0.7543859649122807\n",
      "328_788: 0.546875\n"
     ]
    }
   ],
   "source": [
    "# pair of users: similarity\n",
    "for k,v in minhash_sim_100_threshold.items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e428a19",
   "metadata": {},
   "source": [
    "##### *Report the number of False Positives (FP) and False Negatives (FN) (against the exact Jaccard similarity)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf8cbd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20110 False Positives (FP) and 408662 False Negatives (FN) (against the exact Jaccard similarity).\n"
     ]
    }
   ],
   "source": [
    "# execute function\n",
    "FP, FN = compute_the_number_of_false_positives_and_false_negatives(jaccard_sim, minhash_sim_100)\n",
    "\n",
    "# print\n",
    "print(f'There are {FP} False Positives (FP) and {FN} False Negatives (FN) (against the exact Jaccard similarity).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26be3c8",
   "metadata": {},
   "source": [
    "##### *Report the average number of False Positives (FP) and False Negatives (FN) for 5 different runs using different functions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b978bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of False Positives is 13898, while the average number of False Negatives is 415016.\n",
      "\n",
      "Elapsed time: 112 secs.\n"
     ]
    }
   ],
   "source": [
    "# start time\n",
    "st = time.time()\n",
    "\n",
    "# initialize empty lists\n",
    "# to store FP and FN values\n",
    "false_positives = []\n",
    "false_negatives = []\n",
    "\n",
    "for i in range(5):\n",
    "    # compute user similarity using MinHash signatures\n",
    "    minhash_sim_100, minhash_sim_100_threshold = user_similarity_using_min_hash_signatures(user_movies,100)\n",
    "    # compute false positives and false negatives\n",
    "    FP, FN = compute_the_number_of_false_positives_and_false_negatives(jaccard_sim, minhash_sim_100)\n",
    "    # append the values from each iteration\n",
    "    false_positives.append(FP)\n",
    "    false_negatives.append(FN)\n",
    "\n",
    "# calculate the averages\n",
    "FP_avg = round(np.mean(false_positives))\n",
    "FN_avg = round(np.mean(false_negatives))\n",
    "\n",
    "# end time\n",
    "et = time.time()\n",
    "\n",
    "# print\n",
    "print(f'The average number of False Positives is {FP_avg}, while the average number of False Negatives is {FN_avg}.')\n",
    "print()\n",
    "print(f'Elapsed time: {round(et-st)} secs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e015bba1",
   "metadata": {},
   "source": [
    "### *Using 200 Hash Functions* <a class='anchor' id='200_hash_functions'></a>\n",
    "\n",
    "##### *Compute user similarity using MinHash signatures*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9058bd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute function\n",
    "minhash_sim_200, minhash_sim_200_threshold = user_similarity_using_min_hash_signatures(user_movies,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e05081",
   "metadata": {},
   "source": [
    "##### *Display pair of users with a similarity score of at least 50%*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "822553e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408_898: 0.762114537444934\n",
      "328_788: 0.5230769230769231\n"
     ]
    }
   ],
   "source": [
    "# pair of users: similarity\n",
    "for k,v in minhash_sim_200_threshold.items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aa6e75",
   "metadata": {},
   "source": [
    "##### *Report the number of False Positives (FP) and False Negatives (FN) (against the exact Jaccard similarity)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59541780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7490 False Positives (FP) and 421558 False Negatives (FN) (against the exact Jaccard similarity).\n"
     ]
    }
   ],
   "source": [
    "# execute function\n",
    "FP, FN = compute_the_number_of_false_positives_and_false_negatives(jaccard_sim, minhash_sim_200)\n",
    "\n",
    "# print\n",
    "print(f'There are {FP} False Positives (FP) and {FN} False Negatives (FN) (against the exact Jaccard similarity).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f5ef61",
   "metadata": {},
   "source": [
    "##### *Report the average number of False Positives (FP) and False Negatives (FN) for 5 different runs using different functions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb03ba6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of False Positives is 5173, while the average number of False Negatives is 423885.\n",
      "\n",
      "Elapsed time: 208 secs.\n"
     ]
    }
   ],
   "source": [
    "# start time\n",
    "st = time.time()\n",
    "\n",
    "# initialize empty lists\n",
    "# to store FP and FN values\n",
    "false_positives = []\n",
    "false_negatives = []\n",
    "\n",
    "for i in range(5):\n",
    "    # compute user similarity using MinHash signatures\n",
    "    minhash_sim_200, minhash_sim_200_threshold = user_similarity_using_min_hash_signatures(user_movies,200)\n",
    "    # compute false positives and false negatives\n",
    "    FP, FN = compute_the_number_of_false_positives_and_false_negatives(jaccard_sim, minhash_sim_200)\n",
    "    # append the values from each iteration\n",
    "    false_positives.append(FP)\n",
    "    false_negatives.append(FN)\n",
    "\n",
    "# calculate the averages\n",
    "FP_avg = round(np.mean(false_positives))\n",
    "FN_avg = round(np.mean(false_negatives))\n",
    "\n",
    "# end time\n",
    "et = time.time()\n",
    "\n",
    "# print\n",
    "print(f'The average number of False Positives is {FP_avg}, while the average number of False Negatives is {FN_avg}.')\n",
    "print()\n",
    "print(f'Elapsed time: {round(et-st)} secs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee30f38",
   "metadata": {},
   "source": [
    "### *Comment*  <a class='anchor' id='comment_1'></a>\n",
    "\n",
    "- *Let's observe the average results obtained from using 50, 100 and 200 hash functions*\n",
    "- *There are two (2) observations here:*\n",
    "    - *1. The more hash functions we use, the smaller the number of False Positives (36228 > 13898 > 5173)*\n",
    "    - *2. The more hash functions we use, the higher the number of False Negatives (392275 < 415016 < 423885)*\n",
    "- *By adding more hash functions, we \"build\" additional layers of checking, and hence MinHash becomes a better filtering mechanism*\n",
    "- *On the other hand, this increases the false negative rate, because the requirement for a full signature match is becoming more stringent and less likely*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f8bfc4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## *Locate Similar Users Using LSH Index* <a class='anchor' id='lsh_similarity'></a>\n",
    "\n",
    "### *LSH Instance 1* <a class='anchor' id='lsh_instance_1'></a>\n",
    "\n",
    "- $b = 25$\n",
    "- $r = 8$\n",
    "\n",
    "##### *Locate similar users using LSH index*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74480b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables\n",
    "b, r = 25, 8\n",
    "\n",
    "# execute function\n",
    "lsh_sim_258_threshold, true_pairs, similarity_evaluations = user_similarity_using_lsh(user_movies, b, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c08f195",
   "metadata": {},
   "source": [
    "##### *Display pairs of users with a similarity score of at least 50%*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69720788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408_898: 0.8387096774193549\n",
      "489_587: 0.6299212598425197\n",
      "554_764: 0.5170068027210885\n"
     ]
    }
   ],
   "source": [
    "# pair of users: similarity\n",
    "for k,v in lsh_sim_258_threshold.items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f78b86f",
   "metadata": {},
   "source": [
    "##### *Report the average number of true pairs (TP) and similarity evaluations for 5 different runs using different functions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ac529ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of true pairs is 3, while the average number of similarity evaluations is 40.\n",
      "\n",
      "Elapsed time: 169 secs.\n"
     ]
    }
   ],
   "source": [
    "# start time\n",
    "st = time.time()\n",
    "\n",
    "# initialize empty lists to store\n",
    "# the number of true pairs\n",
    "# and the number of similarity evaluations\n",
    "true_positives = []\n",
    "sim_evaluations = []\n",
    "\n",
    "for i in range(5):\n",
    "    # locate similar users using LSH index\n",
    "    _, true_pairs, similarity_evaluations = user_similarity_using_lsh(user_movies, b, r)\n",
    "    # append the values from each iteration\n",
    "    true_positives.append(true_pairs)\n",
    "    sim_evaluations.append(similarity_evaluations)\n",
    "\n",
    "# calculate the averages\n",
    "TP_avg = round(np.mean(true_positives))\n",
    "SE_avg = round(np.mean(sim_evaluations))\n",
    "\n",
    "# end time\n",
    "et = time.time()\n",
    "\n",
    "# print\n",
    "print(f'The average number of true pairs is {TP_avg}, while the average number of similarity evaluations is {SE_avg}.')\n",
    "print()\n",
    "print(f'Elapsed time: {round(et-st)} secs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cede74d7",
   "metadata": {},
   "source": [
    "### *LSH Instance 2*  <a class='anchor' id='lsh_instance_2'></a>\n",
    "\n",
    "- $b = 40$\n",
    "- $r = 5$\n",
    "\n",
    "##### *Locate similar users using LSH index*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d72e0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables\n",
    "b, r = 40, 5\n",
    "\n",
    "# execute function\n",
    "lsh_sim_405_threshold, true_pairs, similarity_evaluations = user_similarity_using_lsh(user_movies, b, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174c381c",
   "metadata": {},
   "source": [
    "##### *Display pairs of users with a similarity score of at least 50%*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92ad0f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408_898: 0.8387096774193549\n",
      "328_788: 0.6729559748427673\n",
      "489_587: 0.6299212598425197\n",
      "600_826: 0.5454545454545454\n",
      "451_489: 0.5333333333333333\n",
      "674_879: 0.5217391304347826\n",
      "554_764: 0.5170068027210885\n",
      "197_826: 0.512987012987013\n",
      "197_600: 0.5\n"
     ]
    }
   ],
   "source": [
    "# pair of users: similarity\n",
    "for k,v in lsh_sim_405_threshold.items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de23a807",
   "metadata": {},
   "source": [
    "##### *Report the average number of true pairs (TP) and similarity evaluations for 5 different runs using different functions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "570d0c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of true pairs is 7, while the average number of similarity evaluations is 2192.\n",
      "\n",
      "Elapsed time: 225 secs.\n"
     ]
    }
   ],
   "source": [
    "# start time\n",
    "st = time.time()\n",
    "\n",
    "# initialize empty lists to store\n",
    "# the number of true pairs\n",
    "# and the number of similarity evaluations\n",
    "true_positives = []\n",
    "sim_evaluations = []\n",
    "\n",
    "for i in range(5):\n",
    "    # locate similar users using LSH index\n",
    "    _, true_pairs, similarity_evaluations = user_similarity_using_lsh(user_movies, b, r)\n",
    "    # append the values from each iteration\n",
    "    true_positives.append(true_pairs)\n",
    "    sim_evaluations.append(similarity_evaluations)\n",
    "\n",
    "# calculate the averages\n",
    "TP_avg = round(np.mean(true_positives))\n",
    "SE_avg = round(np.mean(sim_evaluations))\n",
    "\n",
    "# end time\n",
    "et = time.time()\n",
    "\n",
    "# print\n",
    "print(f'The average number of true pairs is {TP_avg}, while the average number of similarity evaluations is {SE_avg}.')\n",
    "print()\n",
    "print(f'Elapsed time: {round(et-st)} secs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457706ca",
   "metadata": {},
   "source": [
    "### *Comment*  <a class='anchor' id='comment_2'></a>\n",
    "\n",
    "- *The space required by minhashes is $O(b*r)$*\n",
    "- *Increasing $b$ gives users mini-signatures more chances to match, so it let’s in candidate pairs with lower similarity scores*\n",
    "- *Increasing $r$ makes the match criteria stricter, restricting to higher similarity scores*\n",
    "- *LSH helps reduce the complexity of comparing all pairs in datasets containing millions or billions of samples to calculate their similarity*\n",
    "- *The solution it provides is an* ***approximate search***\n",
    "- *Rather than comparing every vector in the sample* ***(exhaustive search),*** *it approximates and limits the search scope to only the most relevant vectors*\n",
    "- *Therefore, by using LSH in enormous datasets, we gain computational speed at the cost of some accuracy*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8823ae",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*Thank you!*\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
