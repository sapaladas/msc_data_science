{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ca2fe60",
   "metadata": {},
   "source": [
    "# Summarizing Glassdoor Reviews\n",
    "\n",
    "> *Advanced Customer Analytics*  \n",
    "> *MSc in Data Science, Department of Informatics*  \n",
    "> *Athens University of Economics and Business*\n",
    "\n",
    "---\n",
    "\n",
    "<p style='text-align: justify;'>Create a second Python notebook with a function called <code>summarize()</code>. The function should accept as a parameter the path to the csv file created by the first notebook. It should then create a 1-page PDF file that includes a summary of all the reviews in the csv. The nature of the summary is entirely up to you. It can be text-based, visual-based, or a combination of both. It is also up to you to define what is important enough to be included in the summary. Focuss on creating a summary that you think would be the most informative for customers. The creation of the PDF should be done through the notebook. You can use whatever Python-based library that you want.</p>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669df5ba",
   "metadata": {},
   "source": [
    "##### *Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83739496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from fpdf import FPDF\n",
    "from functions.graphs import *\n",
    "from functions.preprocessing import *\n",
    "from functions.frequencies import *\n",
    "from functions.vectorization import *\n",
    "from functions.summarization import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3984319",
   "metadata": {},
   "source": [
    "##### *The filepath where the previously scraped data is located*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56f7f208",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = './data/glassdoor_reviews.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76320cdf",
   "metadata": {},
   "source": [
    "##### *Define a function to create a PDF with a summary of the Glassdoor reviews*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "838aab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(filepath:str):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath: str\n",
    "        The local path where the previously scraped data is located\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "    \"\"\"\n",
    "    \n",
    "    # read the data that was scraped from Glassdoor\n",
    "    df = pd.read_csv(filepath, converters={'rating':int, 'date':pd.to_datetime})\n",
    "    \n",
    "    # get number of reviews and avg rating values\n",
    "    # to pass them to the PDF summary creation\n",
    "    no_reviews = str(len(df))\n",
    "    avg_rating = str(round(df.rating.mean(), 2))\n",
    "        \n",
    "    # save an image showing the number of reviews per rating\n",
    "    plot_number_of_reviews_per_rating(df)\n",
    "    \n",
    "    # save an image showing the number of reviews and the average rating per year\n",
    "    plot_number_of_reviews_and_avg_rating_per_year(df)\n",
    "    \n",
    "    # preprocess the reviews,\n",
    "    # convert them to clean sentences,\n",
    "    # and append them to a list\n",
    "    reviews = df.text.apply(text_preprocessing)\n",
    "    \n",
    "    # initialize empty lists\n",
    "    # to store pros and cons of each review\n",
    "    pros = []\n",
    "    cons = []\n",
    "    \n",
    "    # loop through reviews\n",
    "    for review in reviews:\n",
    "        # split on the separator defined during scrape\n",
    "        pros.append(review.split(' *separator* ')[0].strip())\n",
    "        cons.append(review.split(' *separator* ')[1].strip())\n",
    "    \n",
    "    # convert lists to single text\n",
    "    pros_sent = ' '.join(pros) # str of pros\n",
    "    cons_sent = ' '.join(cons) # str of cons\n",
    "\n",
    "    # https://spacy.io/usage/models\n",
    "    # trained pipeline for the english language\n",
    "    nlp = spacy.load('en_core_web_lg')\n",
    "    \n",
    "    # list of english stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # count how many times each word appears,\n",
    "    # and also returns the result in a dataframe\n",
    "    _, _, df_pros = count_word_frequencies(pros, stop_words, nlp)\n",
    "    _, _, df_cons = count_word_frequencies(cons, stop_words, nlp)\n",
    "    \n",
    "    # get top k words appearing ONLY in pros or cons\n",
    "    df_distinct_pros, df_distinct_cons = get_top_k_distinct_pros_and_cons_words(df_pros, df_cons)\n",
    "    \n",
    "    # get top k words appearing (both in pros or cons, but) MOST FREQUENTLY in pros or cons\n",
    "    df_top_k_pros, df_top_k_cons, _ = get_top_k_mixed_pros_and_cons_words(df_pros, df_cons)\n",
    "    \n",
    "    # save an image showing...\n",
    "    # top k words appearing ONLY in pros\n",
    "    plot_top_k_words(df_distinct_pros)\n",
    "    # top k words appearing ONLY in cons\n",
    "    plot_top_k_words(df_distinct_cons, is_pros=False)\n",
    "    # top k words appearing (both in pros or cons, but) MOST FREQUENTLY in pros\n",
    "    plot_top_k_words(df_top_k_pros, is_distinct=False)\n",
    "    # top k words appearing (both in pros or cons, but) MOST FREQUENTLY in cons\n",
    "    plot_top_k_words(df_top_k_cons, is_pros=False, is_distinct=False)\n",
    "    \n",
    "    # check what people say in pros\n",
    "    # and get the most representative sentences about what they most frequently mention\n",
    "    freq_pros_sentences = get_most_similar_and_frequently_shown_sentences(pros_sent,\n",
    "                                                                          ngram_range=(1,3),\n",
    "                                                                          stop_words=stop_words,\n",
    "                                                                          threshold=0.1)\n",
    "    \n",
    "    # check what people say in cons\n",
    "    # and get the most representative sentences about what they most frequently mention\n",
    "    freq_cons_sentences = get_most_similar_and_frequently_shown_sentences(cons_sent,\n",
    "                                                                          ngram_range=(1,3),\n",
    "                                                                          stop_words=stop_words,\n",
    "                                                                          threshold=0.1)\n",
    "    \n",
    "    # openai - TL;DR summarization\n",
    "    # https://beta.openai.com/examples/default-tldr-summary\n",
    "    summary_pros = openai_tldr_summarization(' '.join(freq_pros_sentences))\n",
    "    summary_cons = openai_tldr_summarization(' '.join(freq_cons_sentences))\n",
    "    \n",
    "    # openai - Grammar correction\n",
    "    # https://beta.openai.com/examples/default-grammar\n",
    "    summary_pros = openai_grammar_correction(summary_pros)\n",
    "    summary_cons = openai_grammar_correction(summary_cons)\n",
    "    \n",
    "    # save pros summary to .txt\n",
    "    with open('./summary/summary_pros.txt', 'w') as text_file:\n",
    "        text_file.write(summary_pros)\n",
    "    \n",
    "    # save cons summary to .txt\n",
    "    with open('./summary/summary_cons.txt', 'w') as text_file:\n",
    "        text_file.write(summary_cons)\n",
    "        \n",
    "    # create a summarization report\n",
    "    create_pdf_report(no_reviews, avg_rating, summary_pros, summary_cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4496cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df00299",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*Thank you!*\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
